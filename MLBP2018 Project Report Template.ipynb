{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Music genre classification*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project our intent is to formulate an implementation of music classification to genres using machine learning techniques. A standard procedure before analyzing audio signals is decomposing the audio. Before the classification, the classifiable song needs to be preprocessed by extracting some distinct characteristics. The songs are decomposed to three different categories - rhythm patterns, chroma and mel frequency cepstral coefficients (MFCCs), which make up the feature space of the model. After the initial feature mapping, some additional features are computed that include variance, maximum, minimum and mean values of the three categories and added to the feature vector. Using these features the classification is implemented with C-support vector classification (SVC), which is first trained with provided labeled data and later used to predict labels of unlabeled data, that is,  predicting which of the 10 music genres considered in the project the songs belong to. The final fitted SVC classifier yielded prediction accuracies of approximately 66%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing music to genres is an usual way of categorizing music since it comes in all different shapes and sizes. Musical genres shares some charasteristic features which include for instance rhythm patterns, timbre and  spectral qualities. \n",
    "\n",
    "Nowadays with growing music streaming platforms with new music flooding in around the clock, a convenient way of organizing and managing music is by categorizing it by its genre. Nevertheless, as no one can keep up with the amount of new music rushing to the market and that is where a genre classifier software would come in handy. Categorizing music by its genre helps for example the service provider to offer more specific and personalized music to the users and makes it easier for the users to find the kind of music they like. However, classifying a song solely on its tonal and rhytmic qualities is a rather hard task to do since there is no definite boundaries between different genres of music. \n",
    "\n",
    "The charasteristics we use in this project for genre classification are rhythm patterns, chroma and MFCCs. Chroma values depict the melody and harmony of the song and consist of 12 classes, one for each semitone, and 4 statistics. The rhythm pattern values consist of how much frequency modulation on specific range of the spectrum is happening and is represented by 24 different bands and 7 statistics. MFCCs are a way of describing the timble of a audio sample. To obtain the MFCCs, the audio is fourier transformed and mapped to mel scale which is then again transformed using discrete cosine transform. The resulting amplitudes are the mel frequency cepstral coefficients. The first 12 MFCCs with 4 statistics are inlcuded in the feature vector. Combining all the features we end up with a 264 dimensional feature vector [1].\n",
    "\n",
    "The goal is to map each feature vector to the correct corresponding label. We implement a model which takes a feature vector as input and returns a vector with its value correspong to probability of the input song belonging to  each genre. The label space consist of most common 10 genres which are numbered from one to ten:\n",
    "\n",
    "1. Pop_Rock\n",
    "\n",
    "2. Electronic\n",
    "\n",
    "3. Rap\n",
    "\n",
    "4. Jazz\n",
    "\n",
    "5. Latin\n",
    "\n",
    "6. RnB\n",
    "\n",
    "7. International\n",
    "\n",
    "8. Country\n",
    "\n",
    "9. Reggae\n",
    "\n",
    "10. Blues\n",
    "\n",
    "In section 2 we overview the given dataset and preprocess the feature vectors to a more suitable format. The classifier and other methods used in this project are described and evaluated in section 3 and in section 4 we present the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Background, problem statement, motivation, many references, description of\n",
    "contents. Introduces the reader to the topic and the broad context within which your\n",
    "research/project fits*\n",
    "*- What do you hope to learn from the project?*\n",
    "*- What question is being addressed?*\n",
    "*- Why is this task important? (motivation)*\n",
    "*Keep it short (half to 1 page).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import all the nececcary libraries. The libraries include Scikit-learn (abbreviated sklearn) which is a machine learning library that contains all the required preprocessing and classification algorithms,  NumPy, a essential library for mathematical functions and matrix calculations, Pandas for data manipulation and finally, matplotlib for plotting.\n",
    "\n",
    "After importing the data we can check its dimensions - the feature matrices $ F \\in \\mathbb{R}^{n \\times 264}$ consist of $n$ 264 dimensional feature vectors as stated before, where $n$ denotes the number of entries and is 4363 for the train data and 6544 for the test data. The train label data is accordingly a 4363 values long vector with its values beging integers ranging from 1 to 10.  As we plot the train labels to a bar chart, a major imbalance is noticable. Class 1 entries make up about half of the train data whereas classes 9 and 10 have under 100 occurrences.\n",
    "\n",
    "\n",
    "*Briefly describe data (class distribution, dimensionality) and how will it affect\n",
    "classification. Visualize the data. Donâ€™t focus too much on the meaning of the features,\n",
    "unless you want to.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "014a593ce82d342a60d749c7a2c46b7c",
     "grade": true,
     "grade_id": "cell-c3ef844c17cf4a1e",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 264)\n",
      "(6544, 264)\n",
      "(4363, 1)\n"
     ]
    }
   ],
   "source": [
    "df_data=pd.read_csv('train_data.csv',header=None)\n",
    "df_label=pd.read_csv('train_labels.csv',header=None)\n",
    "df_test=pd.read_csv('test_data.csv',header=None)\n",
    "labels=df_label.values\n",
    "features=df_data.values\n",
    "test_features=df_test.values\n",
    "\n",
    "print(features.shape)\n",
    "print(test_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADZpJREFUeJzt3X+o3fV9x/Hna6bdVrthJFFcEnbdCF3doFaCdROGm8Ofo3F/CAqrQRzZH7ZrR2Gk/cfRUvCPrduETshqZmROEWsx1FAbsoLsj3ZeW/FHbTFYp7fJzO3S2TJhndt7f9xv1tPkJvfm/jgnyfv5gMs553M/53w/XxLuM9/v95ybVBWSpH5+ZtILkCRNhgGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktTUmkkv4GTWrVtXU1NTk16GJJ1Rnnnmme9X1fqF5p3WAZiammJ6enrSy5CkM0qSf13MPE8BSVJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlOn9SeBl2tqxxOrvo1X775x1bchSavBIwBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1NSCAUiyKclXk7yU5MUkHx3Gz0+yL8nLw+3aYTxJ7klyIMlzSS4bea1tw/yXk2xbvd2SJC1kMUcAbwMfr6r3AlcAdya5BNgB7K+qzcD+4THA9cDm4Ws7cC/MBQO4C/gAcDlw19FoSJLGb8EAVNWhqvrGcP9HwEvABmArsHuYthu4abi/FXig5nwNOC/JRcC1wL6qOlJVPwD2Adet6N5IkhbtlK4BJJkC3g98Hbiwqg7BXCSAC4ZpG4DXR542M4ydaFySNAGLDkCSdwNfAD5WVT882dR5xuok48duZ3uS6STTs7Ozi12eJOkULSoASd7B3A//B6vqsWH4jeHUDsPt4WF8Btg08vSNwMGTjP+UqtpZVVuqasv69etPZV8kSadgMe8CCnAf8FJVfXbkW3uAo+/k2QY8PjJ+2/BuoCuAN4dTRE8C1yRZO1z8vWYYkyRNwGL+T+ArgQ8Bzyd5dhj7JHA38EiSO4DXgJuH7+0FbgAOAG8BtwNU1ZEknwaeHuZ9qqqOrMheSJJO2YIBqKp/Zv7z9wBXzzO/gDtP8Fq7gF2nskBJ0urwk8CS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTCwYgya4kh5O8MDL250m+l+TZ4euGke99IsmBJN9Jcu3I+HXD2IEkO1Z+VyRJp2IxRwD3A9fNM/5XVXXp8LUXIMklwC3Arw/P+dsk5yQ5B/gccD1wCXDrMFeSNCFrFppQVU8lmVrk620FHq6q/wK+m+QAcPnwvQNV9QpAkoeHud865RVLklbEcq4BfDjJc8MporXD2Abg9ZE5M8PYicaPk2R7kukk07Ozs8tYniTpZJYagHuBXwUuBQ4BfzmMZ565dZLx4werdlbVlqrasn79+iUuT5K0kAVPAc2nqt44ej/J3wFfGh7OAJtGpm4EDg73TzQuSZqAJR0BJLlo5OEfAEffIbQHuCXJzya5GNgM/AvwNLA5ycVJ3sncheI9S1+2JGm5FjwCSPIQcBWwLskMcBdwVZJLmTuN8yrwxwBV9WKSR5i7uPs2cGdV/c/wOh8GngTOAXZV1YsrvjeSpEVbzLuAbp1n+L6TzP8M8Jl5xvcCe09pdZKkVeMngSWpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLU1IIBSLIryeEkL4yMnZ9kX5KXh9u1w3iS3JPkQJLnklw28pxtw/yXk2xbnd2RJC3WYo4A7geuO2ZsB7C/qjYD+4fHANcDm4ev7cC9MBcM4C7gA8DlwF1HoyFJmowFA1BVTwFHjhneCuwe7u8GbhoZf6DmfA04L8lFwLXAvqo6UlU/APZxfFQkSWO01GsAF1bVIYDh9oJhfAPw+si8mWHsROOSpAlZ6YvAmWesTjJ+/Ask25NMJ5menZ1d0cVJkn5iqQF4Yzi1w3B7eBifATaNzNsIHDzJ+HGqamdVbamqLevXr1/i8iRJC1lqAPYAR9/Jsw14fGT8tuHdQFcAbw6niJ4Erkmydrj4e80wJkmakDULTUjyEHAVsC7JDHPv5rkbeCTJHcBrwM3D9L3ADcAB4C3gdoCqOpLk08DTw7xPVdWxF5YlSWO0YACq6tYTfOvqeeYWcOcJXmcXsOuUVidJWjV+EliSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqygBIUlMGQJKaMgCS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpoyAJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDVlACSpKQMgSU0ZAElqas2kF3C2mtrxxKpv49W7b1z1bUg6e3kEIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDW1rAAkeTXJ80meTTI9jJ2fZF+Sl4fbtcN4ktyT5ECS55JcthI7IElampU4Avidqrq0qrYMj3cA+6tqM7B/eAxwPbB5+NoO3LsC25YkLdFqnALaCuwe7u8GbhoZf6DmfA04L8lFq7B9SdIiLDcABXwlyTNJtg9jF1bVIYDh9oJhfAPw+shzZ4axn5Jke5LpJNOzs7PLXJ4k6USW+7uArqyqg0kuAPYl+fZJ5maesTpuoGonsBNgy5Ytx31fkrQylnUEUFUHh9vDwBeBy4E3jp7aGW4PD9NngE0jT98IHFzO9iVJS7fkACQ5N8kvHL0PXAO8AOwBtg3TtgGPD/f3ALcN7wa6Anjz6KkiSdL4LecU0IXAF5McfZ1/rKovJ3kaeCTJHcBrwM3D/L3ADcAB4C3g9mVsW5K0TEsOQFW9ArxvnvF/B66eZ7yAO5e6PUnSyvKTwJLUlAGQpKYMgCQ1ZQAkqSkDIElNGQBJasoASFJTBkCSmjIAktSUAZCkpgyAJDW13P8PQKehqR1PrPo2Xr37xlXfhqTV5RGAJDVlACSpKQMgSU0ZAElqygBIUlO+C0haAb7zSmciA6AV5Q9C6czhKSBJasoASFJTngLSWcPTT9Kp8QhAkpryCEDSknnUdWbzCECSmjIAktSUAZCkpgyAJDXlRWDpDOeFWC2VRwCS1JQBkKSmDIAkNWUAJKkpLwJLOiN58Xv5DIAknaKzJT6eApKkpgyAJDVlACSpqbEHIMl1Sb6T5ECSHePeviRpzlgDkOQc4HPA9cAlwK1JLhnnGiRJc8Z9BHA5cKCqXqmqHwMPA1vHvAZJEuMPwAbg9ZHHM8OYJGnMUlXj21hyM3BtVf3R8PhDwOVV9ZGROduB7cPD9wDfGdsCJ2sd8P1JL2IC3O9euu43jHfff7mq1i80adwfBJsBNo083ggcHJ1QVTuBneNc1OkgyXRVbZn0OsbN/e6l637D6bnv4z4F9DSwOcnFSd4J3ALsGfMaJEmM+Qigqt5O8mHgSeAcYFdVvTjONUiS5oz9dwFV1V5g77i3ewZod9pr4H730nW/4TTc97FeBJYknT78VRCS1JQBmLAkm5J8NclLSV5M8tFJr2mckpyT5JtJvjTptYxLkvOSPJrk28Of+29Oek3jkORPh7/jLyR5KMnPTXpNqyHJriSHk7wwMnZ+kn1JXh5u105yjUcZgMl7G/h4Vb0XuAK4s9mvx/go8NKkFzFmfwN8uap+DXgfDfY/yQbgT4AtVfUbzL0J5JbJrmrV3A9cd8zYDmB/VW0G9g+PJ84ATFhVHaqqbwz3f8TcD4MWn45OshG4Efj8pNcyLkl+Efht4D6AqvpxVf3HZFc1NmuAn0+yBngXx3wG6GxRVU8BR44Z3grsHu7vBm4a66JOwACcRpJMAe8Hvj7ZlYzNXwN/BvzvpBcyRr8CzAJ/P5z6+nyScye9qNVWVd8D/gJ4DTgEvFlVX5nsqsbqwqo6BHP/6AMumPB6AANw2kjybuALwMeq6oeTXs9qS/L7wOGqembSaxmzNcBlwL1V9X7gPzlNTgespuGc91bgYuCXgHOT/OFkVyUDcBpI8g7mfvg/WFWPTXo9Y3Il8MEkrzL3W2F/N8k/THZJYzEDzFTV0aO8R5kLwtnu94DvVtVsVf038BjwWxNe0zi9keQigOH28ITXAxiAiUsS5s4Hv1RVn530esalqj5RVRuraoq5i4H/VFVn/b8Iq+rfgNeTvGcYuhr41gSXNC6vAVckedfwd/5qGlz8HrEH2Dbc3wY8PsG1/L+xfxJYx7kS+BDwfJJnh7FPDp+Y1tnpI8CDw+/DegW4fcLrWXVV9fUkjwLfYO6db9/kNPxk7EpI8hBwFbAuyQxwF3A38EiSO5iL4c2TW+FP+ElgSWrKU0CS1JQBkKSmDIAkNWUAJKkpAyBJTRkASWrKAEhSUwZAkpr6P2W2Mogo7aPsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2178  618  326  253  214  260  141  195   92   86]\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(values, counts)\n",
    "plt.show()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the range of feature vectors' values varying widely, a normalization of the feature vectors is a good way of improving the performance of ML algorithms. An common way of implementing the normalization is a min-max scaler or by using a sigmoid function. However, with our data with the feature values ranging from minimum of about -1700 and maximum of $10^6$, these functions would \"squishify\" the smaller end values too aggressively such that the many of the data points would become next to useless. That's why we ended up using sklearn's quantile transformer to normalize our data. The scaler transforms the features to a uniform distribution between zero and one spreading the most frequent values with also reducing the impact of outliers, which is also a good way of noise cancellation.\n",
    "\n",
    "After the normalization, a set of additional features are added to each feature vector. The added features include the mean, minimum and maximum values as well as variance for each statistic of all the three different charcteristics (rhythm, chroma and MFCCs) in the feature space.\n",
    "\n",
    "\n",
    "(*- Explain your whole approach (you can include a block diagram showing the steps in your process).* \n",
    "*- What methods/algorithms, why were the methods chosen. *\n",
    "*- What evaluation methodology (cross CV, etc.).*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(x):\n",
    "    quantile_transformer = QuantileTransformer(random_state=0, n_quantiles=100, output_distribution=\"uniform\")\n",
    "    features= quantile_transformer.fit_transform(x)\n",
    "    return features\n",
    "\n",
    "def added_features(x):\n",
    "    xi=[]\n",
    "    for i in range(0,len(x)):\n",
    "        feature_collector=[]\n",
    "        #append all rythm statistics\n",
    "        for j in range (0,168,24):\n",
    "            rythm=np.median(x[i,j:j+24])\n",
    "            mean_rythm=np.mean(x[i,j:j+24])\n",
    "            var_rythm=np.var(x[i,j:j+24])\n",
    "            min_rythm=np.min(x[i,j:j+24])\n",
    "            max_rythm=np.max(x[i,j:j+24])\n",
    "            feature_collector.append(rythm)\n",
    "            feature_collector.append(var_rythm)\n",
    "            feature_collector.append(mean_rythm)\n",
    "            feature_collector.append(min_rythm)\n",
    "            feature_collector.append(max_rythm)\n",
    "            \n",
    "        #append all chroma statistics\n",
    "        for j in range(168,216,12):\n",
    "            chroma=np.median(x[i,j:j+12])\n",
    "            mean_chroma=np.mean(x[i,j:j+12])\n",
    "            var_chroma=np.var(x[i,j:j+12])\n",
    "            min_chroma=np.min(x[i,j:j+12])\n",
    "            max_chroma=np.max(x[i,j:j+12])\n",
    "            feature_collector.append(chroma)\n",
    "            feature_collector.append(mean_chroma)\n",
    "            feature_collector.append(var_chroma)\n",
    "            feature_collector.append(min_chroma)\n",
    "            feature_collector.append(max_chroma)\n",
    "            \n",
    "        #append mfcc\n",
    "        feature_collector.append(np.median(x[i,216:246]))\n",
    "        feature_collector.append(np.min(x[i,216:246]))\n",
    "        feature_collector.append(np.max(x[i,216:246]))\n",
    "        feature_collector.append(np.var(x[i,216:246]))\n",
    "        \n",
    "        xi.append(np.concatenate((feature_collector,x[i]),axis=None))\n",
    "    return np.asarray(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalizing and adding the features, the values are normalized between zero and one, and the dimesion of the feature matrix space $F$ has grown to $\\mathbb{R}^{n \\times 323}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 323)\n"
     ]
    }
   ],
   "source": [
    "features=scale_features(features)\n",
    "features=added_features(features)\n",
    "features,labels=sklearn.utils.shuffle(features,labels)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=svm.SVC(kernel='rbf',C=12,gamma=0.0072, cache_size=5000, decision_function_shape=\"ovo\")\n",
    "y_p=cross_val_predict(clf,features, labels.ravel(), cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for the cross validation\n",
    "\n",
    "\n",
    "(*Summarize the results of the experiments without discussing their implications.*\n",
    "*- Include both performance measures (accuracy and LogLoss).*\n",
    "*- How does it perform on kaggle compared to the train data.*\n",
    "*- Include a confusion matrix.*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706394682557874\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(labels,y_p)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0990399373673057\n"
     ]
    }
   ],
   "source": [
    "#A new classifier with the \"probability\" parametre True\n",
    "clf=svm.SVC(kernel='rbf',C=12,gamma=0.0072, cache_size=5000, probability=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)\n",
    "clf.fit(X_train,y_train)\n",
    "prob_test=clf.predict_proba(X_test)\n",
    "print(log_loss(y_test, prob_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpret and explain your results *\n",
    "\n",
    "*- Discuss the relevance of the performance measures (accuracy and LogLoss) for\n",
    "imbalanced multiclass datasets. *\n",
    "\n",
    "*- How the results relate to the literature. *\n",
    "\n",
    "*- Suggestions for future research/improvement. *\n",
    "\n",
    "*- Did the study answer your questions? *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] MLBP 2018 Data Analysis Project - Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "*Any additional material needed to complete the report can be included here. For example, if you want to keep  additional source code, additional images or plots, mathematical derivations, etc. The content should be relevant to the report and should help explain or visualize something mentioned earlier. **You can remove the whole Appendix section if there is no need for it.** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features=sklearn.preprocessing.minmax_scale(features,feature_range=(0,1))\n",
    "\n",
    "\n",
    "plt.hist(features[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
